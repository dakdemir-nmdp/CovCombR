% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/covcomb.R
\name{fit_covcomb}
\alias{fit_covcomb}
\title{Fit Wishart EM Model}
\usage{
fit_covcomb(
  S_list,
  nu,
  scale_method = "none",
  alpha_normalization = "geometric",
  init_sigma = "identity",
  control = list(),
  se_method = "plugin"
)
}
\arguments{
\item{S_list}{Named list of sample covariance matrices (e.g., from \code{cov(X)}).
Each matrix is a principal submatrix with row/column names identifying observed variables.}

\item{nu}{Named numeric vector of degrees of freedom (sample sizes) for each sample}

\item{scale_method}{Scaling method: \code{"none"} (default) or \code{"estimate"}}

\item{alpha_normalization}{Normalization method for scale factors when
\code{scale_method = "estimate"}. Options:
\itemize{
  \item \code{"geometric"} (default): Constrains the geometric mean to 1,
        i.e., \eqn{(\prod_{k=1}^K \alpha_k)^{1/K} = 1}. Preferred for multiplicative effects.
  \item \code{"arithmetic"}: Constrains the arithmetic mean to 1,
        i.e., \eqn{(1/K) \sum_{k=1}^K \alpha_k = 1}.
}
This parameter is ignored when \code{scale_method = "none"}.}

\item{init_sigma}{Initial covariance matrix or initialization method
(\code{"avg_padded"} or \code{"identity"})}

\item{control}{List of control parameters:
\itemize{
  \item \code{max_iter}: Maximum iterations (default: 500)
  \item \code{tol}: Convergence tolerance (default: 1e-7)
  \item \code{ridge}: Ridge parameter for stability (default: 1e-8)
  \item \code{min_eigen}: Minimum eigenvalue threshold (default: 1e-10)
  \item \code{bootstrap}: Optional list controlling bootstrap SE computation with elements:
    \itemize{
      \item \code{B}: Number of bootstrap replicates (default: 200)
      \item \code{seed}: Optional RNG seed for reproducibility
      \item \code{progress}: Logical; print simple progress updates if \code{TRUE}
      \item \code{verbose}: Logical; emit messages for failed replicates when \code{TRUE}
      \item \code{retain_samples}: Logical; keep the bootstrap sample array in the result when \code{TRUE}
      \item \code{init_sigma}: Initialization passed to bootstrap fits (defaults to the converged \code{Sigma_hat})
    }
}}

\item{se_method}{Standard error method: \code{"none"}, \code{"plugin"} (default),
\code{"bootstrap"}, or \code{"sem"} (experimental).}
}
\value{
Object of class \code{covcomb} containing:
\item{Sigma_hat}{Estimated combined covariance matrix. This is the primary output,
  at the same scale as the input sample covariances. Use this for downstream analysis
  and prediction, or with \code{Sigma_se} for inference.}
\item{S_hat}{Rescaled presentation of \code{Sigma_hat}. When \code{scale_method = "none"}
  or \code{alpha_normalization = "geometric"}, this equals \code{Sigma_hat}. When
  \code{scale_method = "estimate"} with \code{alpha_normalization = "arithmetic"},
  this equals \eqn{S\_hat\_scale \times \Sigma_{hat}}. Users should primarily use
  \code{Sigma_hat} for analysis; \code{S_hat} is provided for compatibility.}
\item{S_hat_scale}{Scalar rescaling factor applied to Sigma_hat. Equals 1 when
  \code{scale_method = "none"} or \code{alpha_normalization = "geometric"}.}
\item{alpha_hat}{Scale factors for each input sample. Equals 1 when \code{scale_method != "estimate"}.}
\item{Sigma_se}{Standard error matrix on the per-df scale (if \code{se_method != "none"}).
  This provides standard errors for \code{Sigma_hat}.}
\item{S_hat_se}{Standard error matrix on the data scale (if \code{se_method != "none"})}
\item{bootstrap}{Bootstrap metadata (if \code{se_method = "bootstrap"})}
\item{bootstrap_samples}{Bootstrap covariance estimates (if \code{retain_samples = TRUE})}
\item{sem}{SEM diagnostics (if \code{se_method = "sem"}), including:
  \itemize{
    \item \code{I_obs}: Observed information matrix in log-Cholesky parameterization
    \item \code{I_com}: Complete-data information matrix
    \item \code{R}: EM rate matrix
    \item \code{condition_number}: Condition number of observed information (for diagnostics)
    \item \code{min_eigenvalue}: Smallest eigenvalue of observed information (for diagnostics)
  }}
\item{convergence}{Convergence information (status, iterations, final change)}
\item{history}{Iteration history (relative change, log-likelihood with constant terms)}
\item{call}{Matched call}
}
\description{
Estimates a common covariance matrix from incomplete sample covariance matrices using
the EM algorithm. Handles missing data patterns and heterogeneous scaling.
}
\details{
The EM algorithm iterates between:
\itemize{
  \item \strong{E-step}: Computes conditional expectations of missing Wishart blocks
  \item \strong{M-step}: Updates covariance matrix and optional scale factors
}

\strong{Standard Errors:}
\itemize{
  \item \code{"plugin"}: Fast, using the closed-form Wishart variance with per-entry
        coverage weights. \strong{Important:} Plugin SEs assume complete data and
        only account for sampling variance, not EM imputation uncertainty. They may
        substantially underestimate true uncertainty for entries with missing data.
        Returns \code{NA} for entries never jointly observed. Use for exploratory
        analysis only.
  \item \code{"bootstrap"}: Parametric bootstrap that simulates new incomplete Wishart
        samples from the fitted model \code{B} times and refits the EM algorithm for
        each replicate. Accounts for both sampling variance and imputation uncertainty.
        \strong{Recommended for formal inference and hypothesis testing.}
  \item \code{"sem"} (experimental): Supplemented EM method (Meng & Rubin, 1991) that
        computes asymptotic standard errors using the observed information matrix.
        Faster than bootstrap but may be less reliable for small samples or weak overlap.
        Uses log-Cholesky parameterization and finite differences to estimate the EM
        rate matrix. Returns diagnostic information (condition number, eigenvalues).
        \strong{Use with caution and validate against bootstrap for critical applications.}
}

Built-in bootstrap SEs can be requested with \code{se_method = "bootstrap"}. The algorithm generates
\code{B} synthetic datasets (default: 200) matching the original missing-pattern structure, refits the EM model for each
replicate, and reports the empirical standard deviation of the resulting covariance estimates.
Bootstrap behaviour can be customised through \code{control$bootstrap}; see the argument details.

SEM standard errors can be requested with \code{se_method = "sem"}. This method is experimental
and provides fast asymptotic approximations. Control parameters can be specified via
\code{control$sem} with elements \code{h} (finite difference step, default 1e-6) and
\code{ridge} (regularization, default uses \code{control$ridge}).
}
\examples{
# Simulate incomplete sample covariance matrices
set.seed(2025)
p <- 8
var_names <- paste0("V", 1:p)
true_Sigma <- diag(p)
dimnames(true_Sigma) <- list(var_names, var_names)
true_Sigma[1:4, 1:4] <- 0.7
diag(true_Sigma) <- 1

# Generate 3 sample covariances with different missing patterns
# Simulate from Wishart, then convert to sample covariances
W1 <- stats::rWishart(1, 50, true_Sigma[1:5, 1:5])[,,1]
S1 <- W1 / 50
dimnames(S1) <- list(var_names[1:5], var_names[1:5])

W2 <- stats::rWishart(1, 60, true_Sigma[3:8, 3:8])[,,1]
S2 <- W2 / 60
dimnames(S2) <- list(var_names[3:8], var_names[3:8])

W3 <- stats::rWishart(1, 55, true_Sigma[c(1,3,5,7), c(1,3,5,7)])[,,1]
S3 <- W3 / 55
dimnames(S3) <- list(var_names[c(1,3,5,7)], var_names[c(1,3,5,7)])

S_list <- list(sample1 = S1, sample2 = S2, sample3 = S3)
nu <- c(sample1 = 50, sample2 = 60, sample3 = 55)

# Fit model
fit <- fit_covcomb(S_list, nu, se_method = "plugin")
print(fit)

# Extract combined covariance estimate (same scale as input sample covariances)
Sigma_combined <- fit$Sigma_hat  # or coef(fit) or fit$S_hat

# The output is at the same scale as input sample covariances
# Compare to true population covariance
print(Sigma_combined)
print(true_Sigma)

# Standard errors (if requested)
if (!is.null(fit$Sigma_se)) {
  print(fit$Sigma_se)
}

# Bootstrap standard errors (more accurate, ~100x slower)
# fit_boot <- fit_covcomb(
#   S_list, nu,
#   se_method = "bootstrap",
#   control = list(bootstrap = list(B = 200, seed = 2025, progress = TRUE))
# )
# fit_boot$Sigma_se  # Bootstrap SEs on per-df scale

}
